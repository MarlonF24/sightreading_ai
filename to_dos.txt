- fix musicxml midi zero division errors
- update complexities, include key/tempo... changes
- when decoding tokens, set instruments to piano for both hands: 
    midi = tokenizer.decode(token_sequence)
    for instrument in midi.instruments:
        instrument.program = 0  # Program 0 = Acoustic Grand Piano
- test model and adjust weights 
- documentation
- upload tokeniser and model to huggingface hub / maybe together # at the end of project maybe and then give links in readme

- save tokenseqs that a model was trained on in database and filter out at dataset creation
- maybe make loading of MyModel and MyTokeniser bulletproof
- do what audiveris says on its website to enhance transcription quality
- import useful constants from packages into own constant aliases
- clean up constants naming
- for generate classmethod catch non existent saved model 
- use data augmentation from miditok !!! transpose to every key and get *14 data scale
- maybe also split scores at repitition lines or others
- maybe split pdfs by pages


INFO:
    - save_pretrained is like save only with the option to push to hub
    - from_pretrained is like initialising via params, but with option to download from hub
    - params is the full tokeniser file containing config, tokenisations, vocab (if pretrained),...

    3 ways of loading/creating a MyTokeniser:
        - pass in config object in initialiser, this is only for new models with only config
            -> enforced that its a special config of MyTokeniserConfig class
        - pass in tokeniser file in params in initialiser
            -> enforced that when the file is unpacked the classes match
        - call from_pretrained (this will actually go use the 2nd option on the classname it finds in the tokeniser file)
            -> enforced that this returnes an object of MyTokeniser

    2 ways of loading/creating a MyModel:
        - pass in config object in initialiser
        - call from_pretrained (this will call the 1st option)
            -> enforced that architecture (if given) is MyModel, else also requires a tokeniser_hash attr in config 
        