- fix musicxml midi zero division errors
- update complexities, include key/tempo... changes
- when decoding tokens, set instruments to piano for both hands: 
    midi = tokenizer.decode(token_sequence)
    for instrument in midi.instruments:
        instrument.program = 0  # Program 0 = Acoustic Grand Piano
- test model and adjust weights 
- documentation
- upload tokeniser and model to huggingface hub / maybe together # at the end of project maybe and then give links in readme

- save tokenseqs that a model was trained on in database and filter out at dataset creation
- maybe make loading of MyModel and MyTokeniser bulletproof
- do what audiveris says on its website to enhance transcription quality
- use data augmentation from miditok 
- write generic clean_up function that takes extention and removes all nonfitting files
- centralise -100 as label padding in constants
- maybe remove unecessary stuff from token files again
- (generally fix:) put length of "[input:....]" computation of how many lines to clear
- force generation to output certain bar length if possible (difficult with BPE ) 
- switch to music21s analyzeStram for metadata
- !!! could be solution: maybe give metadatatokens distinct tokens (dont risk them being taken by BPE)
- statistical evaluation of properties that determine the complexities to find an appropriate weight (or weight function)
- fix false positive skips (stem*extension) is not bulletproof

INFO:
    - training errors with some assertion src < scr... are likely due to wrong max_positions_embedding in model config, or due to token outside of vocab 

    - rn the musicxml splitting option splits not only at every end bar lines but also at repeat ends

    - save_pretrained is like save only with the option to push to hub
    - from_pretrained is like initialising via params, but with option to download from hub
    - params is the full tokeniser file containing config, tokenisations, vocab (if pretrained),...

    3 ways of loading/creating a MyTokeniser:
        - pass in config object in initialiser, this is only for new models with only config
            -> enforced that its a special config of MyTokeniserConfig class
        - pass in tokeniser file in params in initialiser
            -> enforced that when the file is unpacked the classes match
        - call from_pretrained (this will actually go use the 2nd option on the classname it finds in the tokeniser file)
            -> enforced that this returnes an object of MyTokeniser

    2 ways of loading/creating a MyModel:
        - pass in config object in initialiser
        - call from_pretrained (this will call the 1st option)
            -> enforced that architecture (if given) is MyModel, else also requires a tokeniser_hash attr in config 

    pdf preprocessing splits pdfs into groups of pages,
    tradeoff: larger group -> higher likelihood of containing a text containing page that fails group conversion to musicxml, but also makes it less likely that an exercise that goes across multiple pages is split 

    => all input files must contain only exercises with end bar lines at the end, otherwise they will be merged with the following exercise which corrupts the data
        