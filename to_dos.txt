- fix musicxml midi zero division errors
- update complexities, include key/tempo... changes
- when decoding tokens, set instruments to piano for both hands: 
    midi = tokenizer.decode(token_sequence)
    for instrument in midi.instruments:
        instrument.program = 0  # Program 0 = Acoustic Grand Piano
- maybe make all conversion function init parameters arguments of music pipeline function in pipeline.py
- test model and adjust weights 
- documentation
- upload tokeniser and model to huggingface hub / maybe together # at the end of project maybe and then give links in readme
- centralise all hardcoding like file naming conventions like metadata file naming
- use data augmentation from miditok
- check hash of to_dict for false negatives
- think about max_tok_seq_length for dataset
- maybe save whole tokeniser.to_dict() in model
- create constants file to store all formats and constants
- think about what to do with save_with_hash method for tokeniser
- save tokenseqs that a model was trained on in database and filter out at dataset creation
- maybe build checker to validate config format for MyModel
- correct filter for whether we can load a model (which files need to be present?)
- do what audiveris says on its website to enhance transcription quality


INFO:
    - save_pretrained is like save only with the option to push to hub
    - from_pretrained is like initialising via params, but with option to download from hub
    - params is the full tokeniser file containing config, tokenisations, vocab (if pretrained),...